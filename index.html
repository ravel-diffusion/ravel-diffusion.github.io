<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RAVEL: Rare Concept Generation and Editing via Graph-driven Relational Guidance</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">RAVEL: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kavanavenkatesh.github.io/">Kavana Venkatesh</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yusufdalva.github.io/">Yusuf Dalva</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://isminoula.github.io/">Ismini Lourentzou</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://pinguar.org/">Pinar Yanardag</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Virginia Tech,</span>
            <span class="author-block"><sup>2</sup>University of Illinois Urbana-Champaign</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.09614"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.09614"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-widescreen">
    <div class="hero-body">
      <!-- TL;DR Section -->
      <h2 class="title is-5" style="font-weight: 400; text-align: justify; margin-bottom: 20px; color: #444;">
        <strong>TL;DR</strong> We propose a training-free approach that leverages knowledge graph-based Retrieval Augmented Generation to 
        enhance image generation and editing of text-to-image diffusion models. We also introduce a novel RAG context-guided self-correction mechanism. 
        The approach enables generation of contextually and narratively accurate images for
        complex, domain-specific scenarios that standard T2I models struggle with, using simple high-level user prompts.
      </h2>
      <!-- Teaser image -->
      <img id="teaser-image" src="./static/images/ravel-new-teaser.jpg" alt="Teaser Image" style="width: 120%; height: auto;">
      <h2 class="subtitle teaser-caption" style="font-size: 1rem; text-align: justify;">
      We introduce <span class="dnerf">RAVEL</span>, a training-free approach that uses graph-based RAG to enhance T2I models with context-aware guidance.
It improves generation of rare, complex concepts and supports disentangled image editing. A self-correction module further refines visual
and narrative accuracy.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Despite impressive visual fidelity, current text-to-image (T2I) diffusion models struggle to depict rare, complex, 
            or culturally nuanced concepts due to training data limitations. We introduce <span class="dnerf">RAVEL</span>, 
            a training-free framework that significantly improves rare concept generation, context-driven image editing, 
            and self-correction by integrating graph-based retrieval-augmented generation (RAG) into diffusion pipelines. 
            Unlike prior RAG and LLM-enhanced methods reliant on visual exemplars, static captions or pretrained knowledge of models, 
            <span class="dnerf">RAVEL</span> leverages structured knowledge graphs to retrieve compositional, symbolic, and relational context, 
            enabling nuanced grounding even in the absence of visual priors. To further refine generation quality, we propose <span class="dnerf">SRD</span>, 
            a novel self-correction module that iteratively updates prompts via multi-aspect alignment feedback, enhancing attribute accuracy, 
            narrative coherence, and semantic fidelity. Our framework is model-agnostic and compatible with leading diffusion models including Stable Diffusion XL, 
            Flux, and DALL-E 3. We conduct extensive evaluations across three newly proposed benchmarks - <span class="dnerf">MythoBench</span>, 
            <span class="dnerf">Rare-Concept-1K</span>, and <span class="dnerf">NovelBench</span>. <span class="dnerf">RAVEL</span> also consistently 
            outperforms SOTA methods across perceptual, alignment, and LLM-as-a-Judge metrics. These results position <span class="dnerf">RAVEL</span> 
            as a robust paradigm for controllable and interpretable T2I generation in long-tail domains.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <div class="columns is-centered">
        <div class="column">
          <!-- Paper Method Diagram -->
          <h2 class="title is-3 has-text-centered">Method</h2>
          <div class="publication-diagram" style="text-align: center;">
            <img id="method-diagram" src="./static/images/ravel-upd-framework.jpg" alt="Paper Method Diagram" style="width: 100%; height: auto; margin-top: 20px;">
            <p class="teaser-caption" style="font-size: 1rem; line-height: 1.5; text-align: justify; margin-top: 10px; margin-bottom: 20px; color: #444;">
              An overview of our framework: Our (a) image generation and (b) self-correction approaches leverage context-rich data from a knowledge 
              graph to enhance image fidelity, as well as contextual and narrative coherence for complex characters.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-widescreen">
    <!-- Qualitative Results Main Heading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Qualitative Results</h2>
      </div>
    </div>

    <!-- Rare Concept Generation Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">Rare Concept Generation</h3>
      </div>
    </div>

    <!-- Rare Concept Image Generation Results -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <img id="image-generation" src="./static/images/ravel-image-generation.jpg" alt="Rare Concept Generation" style="width: 120%; height: auto;">
          <p class="teaser-caption">
          <p style="font-size: 1rem; line-height: 1.5; text-align: justify; margin-top: 10px; margin-bottom: 20px; color: #444;">
            RAVEL enhances image generation by integrating contextual details often overlooked by standard models for a variety of domains. 
            *Note that the reference images  are shown solely for illustrative purposes and are not used by our framework. 
          </p>
        </div>
      </div>
    </div>

    <!-- Diverse Domains Rare Concept Generation Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">Rare Concept Generation - Diverse Domains</h3>
      </div>
    </div>

    <!-- Diverse Domains Image Generation Results -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <img id="image-generation" src="./static/images/image-gen-other-domains.jpg" alt="Rare Concept Generation - Diverse Domains" style="width: 120%; height: auto;">
          <p class="teaser-caption">
          <p style="font-size: 1rem; line-height: 1.5; text-align: justify; margin-top: 10px; margin-bottom: 20px; color: #444;">
            RAVEL’s effectiveness in generating complex mythological and fictional concepts without prior visual exemplars. The first 3
            rows are global mythology concepts, while the last two rows are the Project Gutenberg novel characters. 
          </p>
        </div>
      </div>
    </div>

    


    <!-- Self-Correction Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">Self-Correcting RAG-Guided Diffusion (SRD)</h3>
      </div>
    </div>
    
    <!-- Self-Correction Results -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <img id="self-correction" src="./static/images/self-correction-new.jpg" alt="Self-Correction Results" style="width: 100%; height: auto; margin-top: 20px;">
          <p class="teaser-caption">
          <p style="font-size: 1rem; line-height: 1.5; text-align: justify; margin-top: 10px; margin-bottom: 20px; color: #444;">
            Our self-correction mechanism ensures accurate depictions of concepts via iterative, context-aware prompt refinement.
          </p>
        </div>
      </div>
    </div>


    <!-- Image Editing -->
    <div class="columns is-centered" id="image-editing" style="margin-top: 30px;">
    <div class="container is-max-widescreen">
      <div class="column">
        <!-- Editing -->
        <h3 class="title is-4 has-text-centered">Editing</h3>
        <img id="editing-results" src="./static/images/ravel-image-editing.jpg" alt="Editing Results" style="width: 100%; height: auto; margin-top: 20px;">
        <h2 class="subtitle result-caption" style="font-size: 1rem; text-align: justify; margin-top: 10px; max-width: 1200px; margin-left: auto; margin-right: auto;">
          Our method enhances disentangled editing by adding relationally accurate elements without explicit instructions, while ControlNet 
          either adds generic objects or fails to make any edit.
        </h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-widescreen">
    <!-- Qualitative Comparison Main Heading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Qualitative Comparison</h2>
      </div>
    </div>

    <!-- Comparison Image -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: justify;">
          <img id="qualitative-comparison" src="./static/images/other-models-new.jpg" alt="Qualitative Comparison" style="width: 100%; height: auto; margin-top: 20px;">
          <p class="teaser-caption">
            Ravel effectively enhances different T2I models-such as SDXL, Flux and Dall-E 3 to accurately generate complex, rare characters across diverse domains.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Comparison Image -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: justify;">
          <img id="qualitative-comparison" src="./static/images/qual-comparison-competitors.jpg" alt="Qualitative Comparison" style="width: 100%; height: auto; margin-top: 20px;">
          <p class="teaser-caption">
          Qualitative Comparison of RAVEL with other RAG-based T2I methods. We compare RAVEL with state-of-the-art RAG-based methods (Re-Imagen, ImageRAG, RDM) 
          and baseline diffusion models (SDXL, Flux) across different rare concept categories - such as mythological characters (Gandabherunda), 
          rare animals (saola, aye-aye lemur), and cultural artifacts (kapala bowl). Baseline and RAG methods frequently hallucinate incorrect attributes 
          (single-headed birds, generic deer, wrong lemur species, ornate non-skull bowls) or generate visually plausible but contextually inaccurate variants 
          due to lack of structured relational knowledge and the available visual exemplars being inconsistent or rare. *Reference images are shown for illustration 
          only and are not used by our method
          </p>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-widescreen">
    <!-- Quantitative Results Main Heading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Quantitative Results</h2>
      </div>
    </div>

  <!-- Explanation for Qualitative Results -->
  <div class="columns is-centered">
    <div class="column">
      <p style="font-size: 1rem; line-height: 1.5; text-align: justify; margin-top: 20px;">
      We conduct a comprehensive evaluation of 'RAVEL' in two stages, assessing both its foundational RAG component and 
      image generation. We benchmark our approach against SOTA T2I models-such as Flux, SDXL, and DALL-E 3 across image generation 
      and two rounds of self-correction. 
      </p>
    </div>
  </div>

   <!-- RAG Evaluation Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">RAG Evaluation</h3>
      </div>
    </div>

   <!-- Explanation for RAG Evaluation -->
    <div class="columns is-centered">
      <div class="column">
        <p style="font-size: 1rem; line-height: 1.5; text-align: justify; margin-top: 20px;">
          We evaluate RAVEL across four benchmarks: the standard T2ICompBench and our three newly proposed benchmarks - MythoBench, Rare-Concept-1K, and NovelBench.
          Each benchmark targets a distinct challenge — compositional accuracy, symbolic complexity, fine-grained rarity, and zero-shot generalization.
          RAVEL consistently outperforms all baselines across metrics like Attribute Accuracy, Context Relevance, and Visual Fidelity.
        </p>
      </div>
    </div>

    
    <!-- RAG Evaluation Table with Scaled Caption -->
    <div class="columns is-centered">
      <div class="column is-narrow">
        <div class="content" style="text-align: center; width: 30%; margin: 0 auto;">
          <img id="rag-evaluation" src="./static/images/ravel-quant-benchmarks.png" alt="Evaluation Across Our New Benchmarks" style="width: 100%; height: auto; margin-top: 20px;">
        </div>
      </div>
    </div>


    <!-- Benchmarking Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">Comparison with SOTA T2I Models</h3>
      </div>
    </div>

    <!-- SOTA Comparison Table -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <img id="sota-benchmarking" src="./static/images/ravel-quant-image-gen.png" alt="SOTA Benchmarking Table" style="width: 100%; height: auto; margin-top: 20px;">
          <p class="teaser-caption" style="font-size: 1rem; line-height: 1.5; text-align: justify; margin-top: 10px; margin-bottom: 20px;">
           We compare <span class="dnerf">RAVEL</span>'s performance on rare concept generation with SOTA T2I models across key quantitative metrics. 
          Our method significantly improves text-image alignment and attribute accuracy across multiple diffusion backbones.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{venkatesh2024contextcanvasenhancingtexttoimage,
              title={RAVEL: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG}, 
              author={Kavana Venkatesh and Yusuf Dalva and Ismini Lourentzou and Pinar Yanardag},
              year={2024},
              eprint={2412.09614},
              archivePrefix={arXiv},
              primaryClass={cs.CV},
              url={https://arxiv.org/abs/2412.09614} 
        }
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website, 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
